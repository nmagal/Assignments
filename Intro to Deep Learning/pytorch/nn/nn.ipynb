{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mZlnb6KHixxv",
        "MTcBM1IP-mjV",
        "JHjyiAGgONQo"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yak8fP0wkcMH"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_1ztSbb2QGd"
      },
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pdb \n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from psutil import virtual_memory\n",
        "import os\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSOIgD73REpi"
      },
      "source": [
        "class SetUpColab():\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  #Determines how much ram the runtime has\n",
        "  @staticmethod\n",
        "  def ram_runtime():\n",
        "    ram_gb = virtual_memory().total / 1e9\n",
        "    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "    if ram_gb < 20:\n",
        "      print('Not using a high-RAM runtime')\n",
        "    else:\n",
        "      print('You are using a high-RAM runtime!')\n",
        "  \n",
        "  @staticmethod\n",
        "  def mount_google_drive():\n",
        "    drive.mount('/content/gdrive')\n",
        "  \n",
        "  #Sets up environement for use with kaggle api\n",
        "  @staticmethod\n",
        "  def set_up_kaggle():\n",
        "    !pip uninstall -y kaggle\n",
        "    !pip install --upgrade pip\n",
        "    !pip install kaggle==1.5.6\n",
        "    !mkdir .kaggle\n",
        "\n",
        "    token = {\"username\":\"nicholasmagal\",\"key\":\"9bf671834d75b58fac2b037da15f4cf0\"}\n",
        "    with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "      json.dump(token, file)\n",
        "    \n",
        "    for i in range(2):\n",
        "      !chmod 600 /content/.kaggle/kaggle.json\n",
        "      !cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
        "      !kaggle config set -n path -v /content\n",
        "  \n",
        "  @staticmethod\n",
        "  def change_dir(path):\n",
        "    os.chdir(path)\n",
        "  \n",
        "  #Calls above methods to do a complete Collab setup, ready to run ml models :D Note may want to change this per competition\n",
        "  @staticmethod\n",
        "  def complete_set_up():\n",
        "    SetUpColab.ram_runtime()\n",
        "    #SetUpColab.mount_google_drive()\n",
        "    SetUpColab.set_up_kaggle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hBgflMGROwz"
      },
      "source": [
        "SetUpColab.complete_set_up()\n",
        "data_url = 'idl-fall2021-hw1p2'\n",
        "data_path = '/content/competitions/' + data_url\n",
        "!kaggle competitions download -c idl-fall2021-hw1p2\n",
        "SetUpColab.change_dir(data_path)\n",
        "!unzip idl-fall2021-hw1p2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing"
      ],
      "metadata": {
        "id": "DcDN2Wt3VqeA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEVVjzokifDU"
      },
      "source": [
        "#Overwriting our dataset in order to add context to mel frequencies\n",
        "class UtteranceDatset_v2(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, x_file_path, y_file_path, context, train_mode = True):    \n",
        "    self.context = context\n",
        "\n",
        "    #Flatten and read data and pad \n",
        "    self.X_data = np.concatenate(np.load(x_file_path, allow_pickle=True), axis=0)\n",
        "\n",
        "    if train_mode == True: \n",
        "      self.Y_data = np.concatenate(np.load(y_file_path, allow_pickle=True), axis=0).astype(np.int_)\n",
        "      #Labels must match the size of training data \n",
        "      assert len(self.X_data) == len(self.Y_data),\"Number of data != labels\"\n",
        "      self.Y_data = torch.from_numpy(self.Y_data)\n",
        "\n",
        "    padding = np.zeros((context,40))\n",
        "    self.X_data = np.concatenate((padding,self.X_data), axis = 0)\n",
        "    self.X_data = np.concatenate((self.X_data, padding), axis = 0)\n",
        "    self.X_data = self.X_data.astype(np.float32)\n",
        "    self.X_data = torch.from_numpy(self.X_data)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return (len(self.X_data)-(2*self.context))\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    if train_mode == True:\n",
        "      #Index pattern used to account for padding \n",
        "      return (self.X_data[idx:2*self.context+idx+1, :].flatten(),self.Y_data[idx])\n",
        "    else:\n",
        "      return (self.X_data[idx:2*self.context+idx+1, :].flatten()) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOQ1FbnG_K21"
      },
      "source": [
        "class ModelComponents():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  @staticmethod\n",
        "  def create_data_loaders(train_data_path, train_lables_path, val_data_path, val_data_labels_path, test_data_path, context_size):\n",
        "    \n",
        "    #Creating Datasets\n",
        "    training_data = UtteranceDatset_v2(train_data_path,\n",
        "                                   train_lables_path,\n",
        "                                   data_context_size)\n",
        "\n",
        "    validation_data = UtteranceDatset_v2(val_data_path,\n",
        "                                     val_data_labels_path,\n",
        "                                     data_context_size)\n",
        "\n",
        "    test_data = UtteranceDatset_Test_Data(test_data_path,\n",
        "                                      data_context_size, train_mode = False)\n",
        "    \n",
        "    #Creating Dataloaders\n",
        "    training_data_loader = torch.utils.data.DataLoader(training_data,\n",
        "                                                   batch_size = 128,\n",
        "                                                   shuffle = True,\n",
        "                                                   num_workers = 1,\n",
        "                                                   pin_memory = True)\n",
        "\n",
        "    validation_data_loader = torch.utils.data.DataLoader(validation_data,\n",
        "                                                   batch_size = 128,\n",
        "                                                   shuffle = False,\n",
        "                                                   num_workers = 1,\n",
        "                                                   pin_memory = True)\n",
        "    \n",
        "    test_data_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                                   batch_size = 128,\n",
        "                                                   shuffle = False,\n",
        "                                                   num_workers = 1,\n",
        "                                                   pin_memory = True)\n",
        "    \n",
        "    return(training_data_loader,validation_data_loader,test_data_loader)\n",
        "    \n",
        "data_context_size = 20 \n",
        "training_data_loader, validation_data_loader, test_data_loader = ModelComponents.create_data_loaders(\"train.npy\",\"train_labels.npy\",\"dev.npy\",\"dev_labels.npy\",\"test.npy\",data_context_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTz71D2yPxE3"
      },
      "source": [
        "#Refers to how many frames we pad our training example with\n",
        "data_context_size = 20 \n",
        "\n",
        "training_data = UtteranceDatset_v2(\"train.npy\",\n",
        "                                   \"train_labels.npy\",\n",
        "                                   data_context_size)\n",
        "\n",
        "validation_data = UtteranceDatset_v2(\"dev.npy\",\n",
        "                                     \"dev_labels.npy\",\n",
        "                                     data_context_size)\n",
        "\n",
        "test_data = UtteranceDatset_Test_Data(\"test.npy\",\n",
        "                                      data_context_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdBAyFUuqGCA"
      },
      "source": [
        "training_data_loader = torch.utils.data.DataLoader(training_data,\n",
        "                                                   batch_size = 128,\n",
        "                                                   shuffle = True,\n",
        "                                                   num_workers = 1,\n",
        "                                                   pin_memory = True)\n",
        "\n",
        "validation_data_loader = torch.utils.data.DataLoader(validation_data,\n",
        "                                                   batch_size = 128,\n",
        "                                                   shuffle = False,\n",
        "                                                   num_workers = 1,\n",
        "                                                   pin_memory = True)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                                   batch_size = 128,\n",
        "                                                   shuffle = False,\n",
        "                                                   num_workers = 1,\n",
        "                                                   pin_memory = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBqSAefYfbIV"
      },
      "source": [
        "#Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koQkWXCqhfmj"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_layer_size_0, hidden_layer_size_1, hidden_layer_size_2, hidden_layer_size_3, output_size):\n",
        "    super(MLP,self).__init__()\n",
        "\n",
        "    #Defining layers\n",
        "    self.hidden_layer_0 = nn.Linear(input_size, hidden_layer_size_0)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.bn_0 = nn.BatchNorm1d(num_features=hidden_layer_size_0)\n",
        "    self.hidden_layer_1 = nn.Linear(hidden_layer_size_0, hidden_layer_size_1)\n",
        "    self.bn_1 = nn.BatchNorm1d(num_features=hidden_layer_size_1)\n",
        "    self.hidden_layer_2 = nn.Linear(hidden_layer_size_1, hidden_layer_size_2)\n",
        "    self.bn_2 = nn.BatchNorm1d(num_features=hidden_layer_size_2)\n",
        "    self.hidden_layer_3 = nn.Linear(hidden_layer_size_2, hidden_layer_size_3)\n",
        "    self.bn_3 = nn.BatchNorm1d(num_features=hidden_layer_size_3)\n",
        "    self.hidden_layer_4 = nn.Linear(hidden_layer_size_3,output_size)\n",
        "    self.dropout = nn.Dropout(.5)\n",
        "    \n",
        "  def forward(self, data):\n",
        "    #Hidden Layers\n",
        "    output_hidden_layer_0 = self.hidden_layer_0(data)\n",
        "    bn_0_output = self.bn_0(output_hidden_layer_0)\n",
        "    output_activation_0 = self.activation(bn_0_output)\n",
        "    output_drop_out_0 = self.dropout(output_activation_0)\n",
        "\n",
        "    output_hidden_layer_1 = self.hidden_layer_1(output_drop_out_0)\n",
        "    bn_1_output = self.bn_1(output_hidden_layer_1)\n",
        "    output_activation_1 = self.activation(bn_1_output)\n",
        "    output_drop_out_1 = self.dropout(output_activation_1)\n",
        "\n",
        "    output_hidden_layer_2 = self.hidden_layer_2(output_drop_out_1)\n",
        "    bn_2_output = self.bn_2(output_hidden_layer_2)\n",
        "    output_activation_2 = self.activation(bn_2_output)\n",
        "    output_drop_out_2 = self.dropout(output_activation_2)\n",
        "\n",
        "    output_hidden_layer_3 = self.hidden_layer_3(output_drop_out_2)\n",
        "    bn_3_output = self.bn_3(output_hidden_layer_3)\n",
        "    output_activation_3 = self.activation(bn_3_output)\n",
        "    output_drop_out_3 = self.dropout(output_activation_3)\n",
        "\n",
        "    output_hidden_layer_4 = self.hidden_layer_4(output_drop_out_3)\n",
        "\n",
        "    return(output_hidden_layer_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVbk6v53F_Wp"
      },
      "source": [
        "#Model Parameters \n",
        "input_size = (1+2*data_context_size)*40\n",
        "h_0_size = 2048\n",
        "h_1_size = 2048\n",
        "h_2_size = 1024\n",
        "h_3_size = 512\n",
        "output_size = 71 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYHvB-FnDU19",
        "outputId": "fadf696d-6857-4b1e-e8a1-5319dd1efdcf"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "mlp_model = MLP(input_size, h_0_size, h_1_size,h_2_size,h_3_size,output_size)\n",
        "mlp_model.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mlp_model.parameters(), lr = .001)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTqAUCvwDW5X"
      },
      "source": [
        "#Training \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ef8jspbCsc3"
      },
      "source": [
        "def SGD(total_epochs, model, loss_function, optimizer, train_loader, val_loader, scheduler):\n",
        "\n",
        "  for epoch_num in range(total_epochs):\n",
        "    train_loss_tracker = 0\n",
        "    test_loss_tracker = 0\n",
        "    starting_time = datetime.now()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      x, y = x.to(device), y.to(device) \n",
        "\n",
        "      train_output = model(x)\n",
        "      train_loss = loss_function(train_output, y)\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss_tracker = train_loss.item() + train_loss_tracker\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      total_validation_examples = 0\n",
        "      total_correct_validation_examples = 0\n",
        "\n",
        "      for x, y in val_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        #Calculating Loss\n",
        "        val_output = model(x)\n",
        "        val_loss = loss_function(val_output, y)\n",
        "        test_loss_tracker = val_loss.item() + test_loss_tracker\n",
        "\n",
        "        #Calculating Accuracy\n",
        "        prediction_logits, prediction_classes = torch.max(val_output,1)\n",
        "        total_validation_examples = total_validation_examples + x.shape[0]\n",
        "        total_correct_validation_examples = total_correct_validation_examples + (prediction_classes==y).sum().item()\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "    val_accuracy = (total_correct_validation_examples/total_validation_examples)\n",
        "\n",
        "    train_loss_tracker = (train_loss_tracker/len(train_loader))\n",
        "    test_loss_tracker = (test_loss_tracker/len(val_loader))\n",
        "\n",
        "    epoch_runtime = datetime.now() - starting_time \n",
        "    print(f'Epoch: {epoch_num} Train Loss: {train_loss_tracker:.4f} Test Loss: {test_loss_tracker:.4f} Val Accuracy: {val_accuracy:.4f}')\n",
        "    print(f'Epoch Runtime {epoch_runtime}')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY1IfcbWPzLJ",
        "outputId": "f8c99185-c46e-446b-d9d2-69707235231b"
      },
      "source": [
        "SGD(20, mlp_model, loss_function, optimizer, training_data_loader, validation_data_loader,scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: 1.2368 Test Loss: 0.9462 Val Accuracy: 0.7089\n",
            "Epoch Runtime 0:15:47.400045\n",
            "Epoch: 1 Train Loss: 1.0565 Test Loss: 0.8883 Val Accuracy: 0.7261\n",
            "Epoch Runtime 0:15:39.445480\n",
            "Epoch: 2 Train Loss: 1.0038 Test Loss: 0.8542 Val Accuracy: 0.7351\n",
            "Epoch Runtime 0:15:33.702358\n",
            "Epoch: 3 Train Loss: 0.9726 Test Loss: 0.8353 Val Accuracy: 0.7413\n",
            "Epoch Runtime 0:15:59.924188\n",
            "Epoch: 4 Train Loss: 0.9507 Test Loss: 0.8198 Val Accuracy: 0.7460\n",
            "Epoch Runtime 0:15:36.706162\n",
            "Epoch: 5 Train Loss: 0.9341 Test Loss: 0.8064 Val Accuracy: 0.7501\n",
            "Epoch Runtime 0:15:42.164236\n",
            "Epoch: 6 Train Loss: 0.9212 Test Loss: 0.7979 Val Accuracy: 0.7519\n",
            "Epoch Runtime 0:15:49.863296\n",
            "Epoch: 7 Train Loss: 0.9107 Test Loss: 0.7910 Val Accuracy: 0.7541\n",
            "Epoch Runtime 0:15:50.827251\n",
            "Epoch: 8 Train Loss: 0.9013 Test Loss: 0.7819 Val Accuracy: 0.7567\n",
            "Epoch Runtime 0:15:46.871681\n",
            "Epoch: 9 Train Loss: 0.8939 Test Loss: 0.7834 Val Accuracy: 0.7571\n",
            "Epoch Runtime 0:15:44.924151\n",
            "Epoch: 10 Train Loss: 0.8873 Test Loss: 0.7726 Val Accuracy: 0.7598\n",
            "Epoch Runtime 0:15:48.076033\n",
            "Epoch: 11 Train Loss: 0.8811 Test Loss: 0.7723 Val Accuracy: 0.7599\n",
            "Epoch Runtime 0:15:53.222760\n",
            "Epoch: 12 Train Loss: 0.8762 Test Loss: 0.7641 Val Accuracy: 0.7620\n",
            "Epoch Runtime 0:15:55.890386\n",
            "Epoch: 13 Train Loss: 0.8715 Test Loss: 0.7643 Val Accuracy: 0.7622\n",
            "Epoch Runtime 0:15:54.658849\n",
            "Epoch: 14 Train Loss: 0.8674 Test Loss: 0.7628 Val Accuracy: 0.7627\n",
            "Epoch Runtime 0:15:57.108630\n",
            "Epoch: 15 Train Loss: 0.8639 Test Loss: 0.7665 Val Accuracy: 0.7627\n",
            "Epoch Runtime 0:15:57.480471\n",
            "Epoch: 16 Train Loss: 0.8608 Test Loss: 0.7595 Val Accuracy: 0.7643\n",
            "Epoch Runtime 0:15:56.787059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yzIAG52vTvi"
      },
      "source": [
        "#Saving Model Performance and Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5cXzqa87uHj"
      },
      "source": [
        "def save_model(model, optimizer, scheduler_state_dict):\n",
        "  torch.save({\n",
        "  'model_state_dict': model.state_dict(),\n",
        "  'optimizer_state_dict': optimizer.state_dict(),\n",
        "  'scheduler_state_dict' : scheduler.state_dict(),\n",
        "  }, \"/content/gdrive/My Drive/IDL/HW/HW1/P2/saves/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrKPGREcvLEE"
      },
      "source": [
        "def predict_classes(model,test_loader):\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    predicted_classes_total = []\n",
        "    \n",
        "    for x in test_loader:\n",
        "      x = x.to(device)\n",
        "      test_out = model(x)\n",
        "      prediction_logits, prediction_classes = torch.max(test_out,1)\n",
        "      prediction_classes = prediction_classes.tolist()\n",
        "      predicted_classes_total.extend(prediction_classes)\n",
        "    \n",
        "    df = pd.DataFrame(predicted_classes_total)\n",
        "    df.columns = ['label']\n",
        "    path = '/content/gdrive/My Drive/IDL/HW/HW1/P2/saves/predicted_classes_yes.csv'\n",
        "    df.to_csv(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Oh9QSoc0ZP"
      },
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "  \n",
        "  checkpoint = torch.load(checkpoint_fpath)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  return model,optimizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYJsGxTcdeIG"
      },
      "source": [
        "model,optimizer = load_ckp(\"/content/gdrive/My Drive/IDL/HW/HW1/P2/saves/model.pt\",mlp_model,optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA7QU7lX8YZ5"
      },
      "source": [
        "#save_model(mlp_model,optimizer,scheduler)\n",
        "predict_classes(model,test_data_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}